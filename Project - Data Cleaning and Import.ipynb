{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SECTION TO CREATE A SAMPLE FILE FROM THE FULL MAP FROM UDACITY\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "DIRECTORY = \"C:\\Projects\\Udacity\\\\\"\n",
    "OSM_FILE = DIRECTORY + \"berlin_germany.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = DIRECTORY + \"berlin_germany_sample.osm\"\n",
    "\n",
    "#set to 1000 for submission file\n",
    "k = 1000 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "DIRECTORY = \"C:\\Projects\\Udacity\\\\\"\n",
    "\n",
    "OSM_PATH = DIRECTORY + \"berlin_germany.osm\"\n",
    "#OSM_PATH = DIRECTORY + \"berlin_germany_sample.osm\"\n",
    "\n",
    "NODES_PATH = DIRECTORY + \"nodes.csv\"\n",
    "NODE_TAGS_PATH = DIRECTORY + \"nodes_tags.csv\"\n",
    "WAYS_PATH = DIRECTORY + \"ways.csv\"\n",
    "WAY_NODES_PATH = DIRECTORY + \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = DIRECTORY + \"ways_tags.csv\"\n",
    "\n",
    "\n",
    "### UPDATED TO ALLOW : and . in one\n",
    "### UPDATED LOWER COLON TO HAVE ANY CHAR LEFT or RIGHT OF COLON (initial colon) (problem chars being checked for already)\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\, \\t\\r\\n]')\n",
    "LOWER_COLON = re.compile(r'^(.)+:(.)+')\n",
    "\n",
    "#SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "#vars that require special cleanup\n",
    "KNOWNLISTTYPES = ['postal_codes']\n",
    "KNOWN_NODEDICTTYPES = ['addr']\n",
    "KNOWN_WAYDICTTYPES = ['addr']\n",
    "\n",
    "## function returns valid attributes and type\n",
    "## perfroms split on first colon for value (if exists), and second part is type, otherwise type is regular\n",
    "def return_corrected_and_type(attribute):\n",
    "    ## ADDED STRIP TO CLEAR EMPTY CHARS AM ENDE STRING\n",
    "    \n",
    "    attribute = attribute.strip()    \n",
    "    m = PROBLEMCHARS.search(attribute)\n",
    "    if m == None:\n",
    "        m = LOWER_COLON.search(attribute)\n",
    "        if m:\n",
    "            attribname = attribute.split(':')\n",
    "            return ':'.join(attribname[1:]), attribname[0]\n",
    "        else:\n",
    "            return attribute, 'regular'\n",
    "    #else:\n",
    "     #   print attribute\n",
    "\n",
    "#Function that performs data cleanup based on attribute/value.\n",
    "def cleanups(attribute, value):\n",
    "    ## if the function returns None this suggests the node contains irrevelant data and will be dismissed \n",
    "    ## an example is invalid postal codes\n",
    "    \n",
    "    ## KEY CLEANUPS\n",
    "    \n",
    "    ## CLEANING POSTAL CODES TO MATCH\n",
    "    if attribute in ['postal_code','addr:postcode', 'postal_codes']:\n",
    "        attribute = 'postcode'\n",
    "    \n",
    "    ## CLEANING COUNTRY TO DE\n",
    "    if attribute in ['country']:\n",
    "        if value in ['Deutschland', 'Germany']:\n",
    "            value = 'DE'\n",
    "\n",
    "    ## PURGING POLISH LOCATIONS THAT USE SIMC ADDRESS CODES\n",
    "    if attribute in ['simc', 'addr:simc', 'city:simc']:\n",
    "        return None\n",
    "\n",
    "    ## if the value is a list type, return corrected name and value \n",
    "    if type(value) is list:\n",
    "        return attribute, value\n",
    "        \n",
    "    ## VALUE TESTING\n",
    "    \n",
    "    # testing for correct postcodes\n",
    "    if attribute == 'postcode':\n",
    "        #postcode should be 5 chars starting with 1\n",
    "        # could convert to an int\n",
    "        if len(value) != 5:\n",
    "            return None\n",
    "        else:\n",
    "            posttoint = int(value)\n",
    "            # testing range, filter out Polish data\n",
    "            if posttoint < 10115 or posttoint > 14199:\n",
    "                return None\n",
    "            \n",
    "    ### correcting the str. at end of street names or Str.\n",
    "    if attribute == 'street' or attribute == 'addr:street':\n",
    "        if 'str.' in value:\n",
    "            value = value.replace('str.', 'straße'.decode('utf8'))\n",
    "        elif ' Str.' in value:\n",
    "            value = value.replace(' Str.', ' Straße'.decode('utf8'))\n",
    "        \n",
    "    return attribute, value\n",
    "\n",
    "## function could be enhanced for other fields that are passing a list\n",
    "def list_data(attribute, value):\n",
    "    taglist = []\n",
    "    if attribute == \"postal_codes\":\n",
    "        for val in value.split(','):\n",
    "            taglist.append(val)\n",
    "    \n",
    "    return taglist\n",
    "\n",
    "#function to return dict data for complex types\n",
    "def dict_data(attribute, value):\n",
    "    dictlist = {}\n",
    "    '''\n",
    "    #For a street we can split the street into name and type - IDEA SCRAPPED\n",
    "    if attribute == 'street':\n",
    "        \n",
    "        vals = value.split(',')\n",
    "\n",
    "        if len(vals) == 2:\n",
    "            valsstreet = vals[0].split(' ')\n",
    "            dictlist['street'], dictlist['housenumber'] = ' '.join(valsstreet[:len(valsstreet)-1]).strip(), valsstreet[len(valsstreet)-1:].strip()\n",
    "            dictlist['city'] = vals[2].strip()\n",
    "\n",
    "            \n",
    "        ## if no split, leave it as is\n",
    "    '''\n",
    "    dictlist[attribute] = value\n",
    "    return dictlist\n",
    "    \n",
    "# main function returns cleaned/wrangled dict of node/node tags or way/way tags\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        ##Assign Node Attributes       \n",
    "        \n",
    "        ## HANDLING FOR ATTRIBUTES THAT ARE MISSING DATA (ie EMPTYS)\n",
    "        for attrib in NODE_FIELDS:\n",
    "            if attrib not in element.attrib:\n",
    "                node_attribs[attrib] = ''\n",
    "            else:\n",
    "                node_attribs[attrib] = element.attrib[attrib]\n",
    "                           \n",
    "        ##Assign Node Tags Attributes\n",
    "        for tag in element.findall(\"tag\"):\n",
    "            tag_d = {}\n",
    "            \n",
    "            ## if the corrected key/type are invalid we do not add them            \n",
    "            if return_corrected_and_type(tag.attrib['k']) != None: \n",
    "                tag_d['id'] = node_attribs['id']\n",
    "                tag_d['key'], tag_d['type'] = return_corrected_and_type(tag.attrib['k']) \n",
    "                \n",
    "                #if key attrib is a knownlist, we can append multiple tags \n",
    "                if tag.attrib['k'] in KNOWNLISTTYPES:\n",
    "                    taglist = list_data(tag.attrib['k'], tag.attrib['v'])\n",
    "                    \n",
    "                    for vals in taglist:\n",
    "                        temp_d = {}\n",
    "                        temp_d[\"id\"] = tag_d[\"id\"]\n",
    "                        temp_d[\"type\"] = tag_d[\"type\"]\n",
    "                        temp_d['key'], temp_d['value'] = cleanups(tag_d['key'], vals)\n",
    "                        tags.append(temp_d)\n",
    "                #same idea for dict. types        \n",
    "                elif tag_d['key'] in KNOWN_NODEDICTTYPES:\n",
    "                    tagdict = dict_data(tag_d['key'], tag.attrib['v'])\n",
    "                    \n",
    "                    for tagkey in tagdict:\n",
    "                        temp_d = {}\n",
    "                        temp_d[\"id\"] = tag_d[\"id\"]\n",
    "                        temp_d[\"type\"] = tag_d[\"type\"]\n",
    "                        temp_d['key'], temp_d['value'] = cleanups(tagkey, tagdict[tagkey])\n",
    "                        tags.append(temp_d)                        \n",
    "                #otherwise add the tag (if the cleanup is valid)\n",
    "                else:     \n",
    "                    tag_d['value'] = tag.attrib['v']                \n",
    "                \n",
    "                    if cleanups(tag_d['key'], tag_d['value']) == None:\n",
    "                        return None\n",
    "                    else:\n",
    "                        tag_d['key'], tag_d['value'] = cleanups(tag_d['key'], tag_d['value'])\n",
    "                    tags.append(tag_d)\n",
    "\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    ## same as if element.tag == node\n",
    "    elif element.tag == 'way':\n",
    "        \n",
    "        for attrib in WAY_FIELDS:\n",
    "            if attrib not in element.attrib:\n",
    "                ## Some early data was missing user attributes\n",
    "                way_attribs[attrib] = ''\n",
    "            else:\n",
    "                way_attribs[attrib] = element.attrib[attrib]\n",
    "\n",
    "        position = 0\n",
    "        for tag in element.findall(\"nd\"):\n",
    "            tag_d = {}\n",
    "            tag_d['id'] = way_attribs['id']\n",
    "            tag_d['node_id'] = tag.attrib['ref']\n",
    "            tag_d['position'] = position\n",
    "            way_nodes.append(tag_d)\n",
    "            position += 1  \n",
    "        \n",
    "        for tag in element.findall(\"tag\"):\n",
    "            tag_d = {}\n",
    "            if return_corrected_and_type(tag.attrib['k']) != None: \n",
    "                tag_d['id'] = way_attribs['id']\n",
    "                tag_d['key'], tag_d['type'] = return_corrected_and_type(tag.attrib['k']) \n",
    "                \n",
    "                if tag.attrib['k'] in KNOWNLISTTYPES:\n",
    "                    taglist = list_data(tag.attrib['k'], tag.attrib['v'])\n",
    "                    \n",
    "                    for vals in taglist:\n",
    "                        temp_d = {}\n",
    "                        temp_d[\"id\"] = tag_d[\"id\"]\n",
    "                        temp_d[\"type\"] = tag_d[\"type\"]\n",
    "                        temp_d['key'], temp_d['value'] = cleanups(tag_d['key'], vals)\n",
    "                        tags.append(temp_d)\n",
    "                        \n",
    "                elif tag_d['key'] in KNOWN_WAYDICTTYPES:\n",
    "                    tagdict = dict_data(tag_d['key'], tag.attrib['v'])\n",
    "                    \n",
    "                    for tagkey in tagdict:\n",
    "                        temp_d = {}\n",
    "                        temp_d[\"id\"] = tag_d[\"id\"]\n",
    "                        temp_d[\"type\"] = tag_d[\"type\"]\n",
    "                        temp_d['key'], temp_d['value'] = cleanups(tagkey, tagdict[tagkey])\n",
    "                        tags.append(temp_d)\n",
    "\n",
    "                else:     \n",
    "                    tag_d['value'] = tag.attrib['v']                \n",
    "                \n",
    "                    if cleanups(tag_d['key'], tag_d['value']) == None:\n",
    "                        return None\n",
    "                    else:\n",
    "                        tag_d['key'], tag_d['value'] = cleanups(tag_d['key'], tag_d['value'])\n",
    "                    tags.append(tag_d)\n",
    "             \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "## FROM UDACITY CASE STUDY\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'wb') as nodes_file, \\\n",
    "        codecs.open(NODE_TAGS_PATH, 'wb') as nodes_tags_file, \\\n",
    "        codecs.open(WAYS_PATH, 'wb') as ways_file, \\\n",
    "        codecs.open(WAY_NODES_PATH, 'wb') as way_nodes_file, \\\n",
    "        codecs.open(WAY_TAGS_PATH, 'wb') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SQL IMPORT STEPS\n",
    "\n",
    "DB_PATH = DIRECTORY + \"berlin_germany.db\"\n",
    "\n",
    "SCHEMA = DIRECTORY + \"schema.sql\"\n",
    "\n",
    "import sqlite3\n",
    "import csv\n",
    "import sys\n",
    "db = sqlite3.connect(DB_PATH)\n",
    "\n",
    "c = db.cursor()\n",
    "\n",
    "##SCHEMA.sql SCRIPT UPDATED TO INCLUDE DROPS IN THE SCRIPT\n",
    "with open(SCHEMA, \"rb\") as f:\n",
    "    c.executescript(f.read())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing nodes\n",
    "with open(NODES_PATH, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        try:\n",
    "            row[\"user\"] = unicode(row[\"user\"], 'utf-8')\n",
    "            c.execute(\"insert into nodes values (?, ?, ?, ?, ?, ?, ?, ?)\", (row[NODE_FIELDS[0]], row[NODE_FIELDS[1]], row[NODE_FIELDS[2]], row[NODE_FIELDS[3]], row[NODE_FIELDS[4]], row[NODE_FIELDS[5]], row[NODE_FIELDS[6]], row[NODE_FIELDS[7]]))\n",
    "        except:\n",
    "            print row\n",
    "            print \"Unexpected error:\", sys.exc_info()\n",
    "            break\n",
    "    db.commit()\n",
    "\n",
    "# importing nodes tags\n",
    "with open(NODE_TAGS_PATH, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        try:\n",
    "            row[\"key\"] = unicode(row[\"key\"], 'utf-8')\n",
    "            row[\"value\"] = unicode(row[\"value\"], 'utf-8')\n",
    "            row[\"type\"] = unicode(row[\"type\"], 'utf-8')\n",
    "            c.execute(\"insert into nodes_tags values (?, ?, ?, ?)\", (row[NODE_TAGS_FIELDS[0]], row[NODE_TAGS_FIELDS[1]], row[NODE_TAGS_FIELDS[2]], row[NODE_TAGS_FIELDS[3]]))\n",
    "        except:\n",
    "            print row\n",
    "            print \"Unexpected error:\", sys.exc_info()\n",
    "            break\n",
    "    db.commit()\n",
    "    \n",
    "# importing ways\n",
    "with open(WAYS_PATH, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        try:\n",
    "            row[\"user\"] = unicode(row[\"user\"], 'utf-8')\n",
    "            c.execute(\"insert into ways values (?, ?, ?, ?, ?, ?)\", (row[WAY_FIELDS[0]], row[WAY_FIELDS[1]], row[WAY_FIELDS[2]], row[WAY_FIELDS[3]], row[WAY_FIELDS[4]], row[WAY_FIELDS[5]]))\n",
    "        except:\n",
    "            print row\n",
    "            print \"Unexpected error:\", sys.exc_info()\n",
    "            break\n",
    "    db.commit()\n",
    "\n",
    "# importing ways_tags tags\n",
    "with open(WAY_TAGS_PATH, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        try:\n",
    "            row[\"key\"] = unicode(row[\"key\"], 'utf-8')\n",
    "            row[\"value\"] = unicode(row[\"value\"], 'utf-8')\n",
    "            row[\"type\"] = unicode(row[\"type\"], 'utf-8')\n",
    "            c.execute(\"insert into ways_tags values (?, ?, ?, ?)\", (row[WAY_TAGS_FIELDS[0]], row[WAY_TAGS_FIELDS[1]], row[WAY_TAGS_FIELDS[2]], row[WAY_TAGS_FIELDS[3]]))\n",
    "        except:\n",
    "            print row\n",
    "            print \"Unexpected error:\", sys.exc_info()\n",
    "            break\n",
    "    db.commit()\n",
    "\n",
    "# importing ways_nodes paths\n",
    "with open(WAY_NODES_PATH, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        try:\n",
    "            c.execute(\"insert into ways_nodes values (?, ?, ?)\", (row[WAY_NODES_FIELDS[0]], row[WAY_NODES_FIELDS[1]], row[WAY_NODES_FIELDS[2]]))\n",
    "        except:\n",
    "            print row\n",
    "            print \"Unexpected error:\", sys.exc_info()\n",
    "            break\n",
    "    db.commit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
